{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "000dc980",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-05T19:02:02.597368Z",
     "iopub.status.busy": "2025-09-05T19:02:02.597070Z",
     "iopub.status.idle": "2025-09-05T19:02:04.641903Z",
     "shell.execute_reply": "2025-09-05T19:02:04.641054Z"
    },
    "papermill": {
     "duration": 2.0498,
     "end_time": "2025-09-05T19:02:04.643543",
     "exception": false,
     "start_time": "2025-09-05T19:02:02.593743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mitsui-commodity-prediction-challenge/target_pairs.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/train_labels.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/train.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/test.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/lagged_test_labels/test_labels_lag_1.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/lagged_test_labels/test_labels_lag_4.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/lagged_test_labels/test_labels_lag_3.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/lagged_test_labels/test_labels_lag_2.csv\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/mitsui_inference_server.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/mitsui_gateway.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/mitsui-commodity-prediction-challenge/kaggle_evaluation/core/generated/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2362e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T19:02:04.649252Z",
     "iopub.status.busy": "2025-09-05T19:02:04.648874Z",
     "iopub.status.idle": "2025-09-05T19:02:40.412875Z",
     "shell.execute_reply": "2025-09-05T19:02:40.411900Z"
    },
    "papermill": {
     "duration": 35.768798,
     "end_time": "2025-09-05T19:02:40.414465",
     "exception": false,
     "start_time": "2025-09-05T19:02:04.645667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running local gateway for testing...\n",
      "Loading training data for simple model...\n",
      "Loaded: train (1961, 558), labels (1961, 425)\n",
      "Training simple reliable predictor...\n",
      "Training 50 models...\n",
      "Trained 10 models...\n",
      "Trained 20 models...\n",
      "Trained 30 models...\n",
      "Trained 40 models...\n",
      "Trained 50 models...\n",
      "Training completed: 50 models, 559 features\n",
      "Simple model training completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import kaggle_evaluation.mitsui_inference_server\n",
    "\n",
    "NUM_TARGET_COLUMNS = 424\n",
    "\n",
    "# Simple global model storage\n",
    "SIMPLE_MODEL = None\n",
    "\n",
    "class SimpleReliablePredictor:\n",
    "    \"\"\"Simple, fast, and reliable predictor for API submission\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.scaler = None\n",
    "        self.feature_columns = []\n",
    "        self.feature_means = {}\n",
    "        self.target_means = {}\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def create_simple_features(self, df, lags_1=None):\n",
    "        \"\"\"Create minimal but effective features\"\"\"\n",
    "        \n",
    "        # Convert to pandas\n",
    "        if isinstance(df, pl.DataFrame):\n",
    "            df = df.to_pandas()\n",
    "        \n",
    "        features = df.copy()\n",
    "        \n",
    "        # Get a few key numeric columns\n",
    "        numeric_cols = [col for col in df.columns if col not in ['date_id'] and \n",
    "                       df[col].dtype in [np.float64, np.int64]]\n",
    "        \n",
    "        # 1. Use most important base features\n",
    "        key_features = []\n",
    "        for col in numeric_cols:\n",
    "            if any(x in col for x in ['LME_', 'US_Stock_', 'FX_']):\n",
    "                key_features.append(col)\n",
    "            if len(key_features) >= 20:  # Limit for speed\n",
    "                break\n",
    "        \n",
    "        # 2. Simple aggregations\n",
    "        lme_cols = [col for col in key_features if col.startswith('LME_')]\n",
    "        if lme_cols:\n",
    "            features['LME_mean'] = features[lme_cols].mean(axis=1)\n",
    "        \n",
    "        us_cols = [col for col in key_features if col.startswith('US_Stock_')]\n",
    "        if us_cols:\n",
    "            features['US_mean'] = features[us_cols[:5]].mean(axis=1)\n",
    "        \n",
    "        fx_cols = [col for col in key_features if col.startswith('FX_')]\n",
    "        if fx_cols:\n",
    "            features['FX_mean'] = features[fx_cols[:5]].mean(axis=1)\n",
    "        \n",
    "        # 3. Use lag1 features (most important!)\n",
    "        if lags_1 is not None and not lags_1.is_empty():\n",
    "            lag_data = lags_1.to_pandas() if isinstance(lags_1, pl.DataFrame) else lags_1\n",
    "            if len(lag_data) > 0:\n",
    "                latest = lag_data.iloc[-1]\n",
    "                # Use a few key lag features\n",
    "                target_cols = [col for col in latest.index if col.startswith('target_')]\n",
    "                if target_cols:\n",
    "                    # Mean of recent targets\n",
    "                    recent_values = [latest[col] for col in target_cols[:10] if not np.isnan(latest[col])]\n",
    "                    if recent_values:\n",
    "                        features['lag1_target_mean'] = np.mean(recent_values)\n",
    "                        features['lag1_target_std'] = np.std(recent_values) if len(recent_values) > 1 else 0.0\n",
    "                    else:\n",
    "                        features['lag1_target_mean'] = 0.0\n",
    "                        features['lag1_target_std'] = 0.0\n",
    "        \n",
    "        # 4. Clean up\n",
    "        features = features.fillna(0.0)\n",
    "        features = features.replace([np.inf, -np.inf], 0.0)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def fit(self, train_data, train_labels):\n",
    "        \"\"\"Fit simple models quickly\"\"\"\n",
    "        print(\"Training simple reliable predictor...\")\n",
    "        \n",
    "        # Take a sample for faster training\n",
    "        sample_size = min(1000, len(train_data))\n",
    "        train_sample = train_data.sample(n=sample_size, random_state=42)\n",
    "        labels_sample = train_labels[train_labels['date_id'].isin(train_sample['date_id'])]\n",
    "        \n",
    "        # Create features\n",
    "        train_features = self.create_simple_features(train_sample)\n",
    "        \n",
    "        # Get feature columns\n",
    "        feature_cols = [col for col in train_features.columns if col not in ['date_id']]\n",
    "        target_cols = [col for col in labels_sample.columns if col.startswith('target_')]\n",
    "        \n",
    "        # Store feature means for missing value imputation\n",
    "        for col in feature_cols:\n",
    "            self.feature_means[col] = train_features[col].mean()\n",
    "        \n",
    "        # Merge data\n",
    "        train_full = train_features.merge(labels_sample, on='date_id', how='left')\n",
    "        \n",
    "        # Simple scaling\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(train_full[feature_cols])\n",
    "        \n",
    "        # Calculate target means\n",
    "        for target in target_cols:\n",
    "            self.target_means[target] = train_full[target].mean()\n",
    "        \n",
    "        # Train models for a subset of targets\n",
    "        max_models = 50  # Very conservative for speed\n",
    "        print(f\"Training {max_models} models...\")\n",
    "        \n",
    "        for i, target in enumerate(target_cols[:max_models]):\n",
    "            y = train_full[target]\n",
    "            mask = ~np.isnan(y)\n",
    "            \n",
    "            if mask.sum() >= 30:\n",
    "                # Simple Ridge model\n",
    "                model = Ridge(alpha=1.0, random_state=42)\n",
    "                model.fit(X_scaled[mask], y[mask])\n",
    "                self.models[target] = model\n",
    "                \n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"Trained {i + 1} models...\")\n",
    "        \n",
    "        self.feature_columns = feature_cols\n",
    "        self.is_fitted = True\n",
    "        \n",
    "        print(f\"Training completed: {len(self.models)} models, {len(feature_cols)} features\")\n",
    "        return self\n",
    "    \n",
    "    def predict_single(self, test_data, lags_1=None, lags_2=None, lags_3=None, lags_4=None):\n",
    "        \"\"\"Make simple predictions\"\"\"\n",
    "        \n",
    "        # Create features\n",
    "        features = self.create_simple_features(test_data, lags_1)\n",
    "        \n",
    "        # Handle missing features\n",
    "        for col in self.feature_columns:\n",
    "            if col not in features.columns:\n",
    "                features[col] = self.feature_means.get(col, 0.0)\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.transform(features[self.feature_columns])\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = {}\n",
    "        \n",
    "        for i in range(NUM_TARGET_COLUMNS):\n",
    "            target = f'target_{i}'\n",
    "            \n",
    "            if target in self.models:\n",
    "                # Use trained model\n",
    "                pred = self.models[target].predict(X_scaled)[0]\n",
    "            else:\n",
    "                # Use target mean or simple heuristic\n",
    "                if target in self.target_means:\n",
    "                    pred = self.target_means[target]\n",
    "                else:\n",
    "                    # Simple heuristic based on lag features\n",
    "                    if 'lag1_target_mean' in features.columns:\n",
    "                        lag_mean = features['lag1_target_mean'].iloc[0]\n",
    "                        pred = lag_mean * 0.8 + np.random.normal(0, 0.001)  # Slight momentum + noise\n",
    "                    else:\n",
    "                        pred = np.random.normal(0, 0.001)  # Small random value\n",
    "            \n",
    "            # Clip extreme values\n",
    "            pred = np.clip(pred, -0.1, 0.1)\n",
    "            predictions[target] = pred\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "def load_and_train_simple_model():\n",
    "    \"\"\"Load and train the simple model\"\"\"\n",
    "    global SIMPLE_MODEL\n",
    "    \n",
    "    print(\"Loading training data for simple model...\")\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        train = pd.read_csv('/kaggle/input/mitsui-commodity-prediction-challenge/train.csv')\n",
    "        train_labels = pd.read_csv('/kaggle/input/mitsui-commodity-prediction-challenge/train_labels.csv')\n",
    "        \n",
    "        print(f\"Loaded: train {train.shape}, labels {train_labels.shape}\")\n",
    "        \n",
    "        # Train model\n",
    "        SIMPLE_MODEL = SimpleReliablePredictor()\n",
    "        SIMPLE_MODEL.fit(train, train_labels)\n",
    "        \n",
    "        print(\"Simple model training completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        # Create dummy model that returns zeros\n",
    "        SIMPLE_MODEL = DummyPredictor()\n",
    "\n",
    "class DummyPredictor:\n",
    "    \"\"\"Fallback predictor that returns small random values\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.is_fitted = True\n",
    "    \n",
    "    def predict_single(self, test_data, lags_1=None, lags_2=None, lags_3=None, lags_4=None):\n",
    "        \"\"\"Return small random predictions\"\"\"\n",
    "        np.random.seed(42)\n",
    "        predictions = {}\n",
    "        for i in range(NUM_TARGET_COLUMNS):\n",
    "            predictions[f'target_{i}'] = np.random.normal(0, 0.001)\n",
    "        return predictions\n",
    "\n",
    "def predict(\n",
    "    test: pl.DataFrame,\n",
    "    label_lags_1_batch: pl.DataFrame,\n",
    "    label_lags_2_batch: pl.DataFrame,\n",
    "    label_lags_3_batch: pl.DataFrame,\n",
    "    label_lags_4_batch: pl.DataFrame,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"Main prediction function with error handling\"\"\"\n",
    "    \n",
    "    global SIMPLE_MODEL\n",
    "    \n",
    "    try:\n",
    "        # Load model on first call\n",
    "        if SIMPLE_MODEL is None:\n",
    "            load_and_train_simple_model()\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = SIMPLE_MODEL.predict_single(\n",
    "            test, \n",
    "            label_lags_1_batch, \n",
    "            label_lags_2_batch, \n",
    "            label_lags_3_batch, \n",
    "            label_lags_4_batch\n",
    "        )\n",
    "        \n",
    "        # Convert to polars DataFrame\n",
    "        result = pl.DataFrame({\n",
    "            f'target_{i}': [predictions[f'target_{i}']] \n",
    "            for i in range(NUM_TARGET_COLUMNS)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in prediction: {e}\")\n",
    "        # Fallback to random predictions\n",
    "        np.random.seed(42)\n",
    "        result = pl.DataFrame({\n",
    "            f'target_{i}': [np.random.normal(0, 0.001)] \n",
    "            for i in range(NUM_TARGET_COLUMNS)\n",
    "        })\n",
    "    \n",
    "    assert isinstance(result, pl.DataFrame)\n",
    "    assert len(result) == 1\n",
    "    assert len(result.columns) == NUM_TARGET_COLUMNS\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Create inference server\n",
    "inference_server = kaggle_evaluation.mitsui_inference_server.MitsuiInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    print(\"Starting inference server for competition...\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    print(\"Running local gateway for testing...\")\n",
    "    inference_server.run_local_gateway(('/kaggle/input/mitsui-commodity-prediction-challenge/',))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13613251,
     "sourceId": 94771,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.689809,
   "end_time": "2025-09-05T19:02:41.247496",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-05T19:01:56.557687",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
